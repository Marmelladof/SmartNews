{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalação das packages e importação das mesmas"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers datasets torch optuna sentencepiece \r\n",
        "import torch\r\n",
        "import optuna\r\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config, Trainer, TrainingArguments, pipeline, EarlyStoppingCallback\r\n",
        "from datasets import load_dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load do dataset \"_multi news_\" da bilbioteca _datasets_ que contem notícias e o respetivo sumário\r\n",
        "<br>O dataset vem com 3 splits, _train, validation e test_\r\n",
        "<br>Para o treino e selecionou-se só parte do dataset devido a este ser muito grande e necessitar de demasiada memória no treino do modelo\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"multi_news\") #load ao dataset\r\n",
        "\r\n",
        "train_size = int(0.05 * len(dataset[\"train\"])) #arranjar x% do tamanho do dataset\r\n",
        "\r\n",
        "reduced_train_dataset = dataset[\"train\"].select(range(train_size)) #selecionar só x% do dataset de treino\r\n",
        "val_dataset = dataset[\"validation\"] #seleccionar o dataset de validação"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função de tokenização usando o modelo  _T5Tokenizer_ e ficheiro de vocabulário _t5-base_\r\n",
        "<br> Retorna _input ids, attention mask e labels_ que são usados no treino do modelo\r\n",
        "<br> Feita a tokenização do dataset de treino e de validação"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\") # carrega o tokenizer T5 com o vocabulário pré-treinado do t5-base\n",
        "    #aqui o max length equivale ao numero de tokens que são aceites em ambos os tokenizers\n",
        "    tokenized_input = tokenizer(batch['document'], padding=True, truncation=True, return_tensors=\"pt\", max_length=512) # faz tokenização das notícias, o que será a \"entrada\" na nossa aplicação\n",
        "    tokenized_target = tokenizer(batch['summary'], padding=True, truncation=True, return_tensors=\"pt\", max_length=150) # faz tokenização dos sumários, ou \"saída\"\n",
        "    return {'input_ids': tokenized_input['input_ids'], 'attention_mask': tokenized_input['attention_mask'], \n",
        "            'labels': tokenized_target['input_ids']} # validar // t5 necessita de input ids, attention mask e labels para treinar\n",
        "\n",
        "tokenized_train_dataset = reduced_train_dataset.map(tokenize, batched=True, batch_size=16) # aqui o map vai aplicar a tokenização a todos os elementos do dataset\n",
        "tokenized_val_dataset = val_dataset.map(tokenize, batched=True, batch_size=16) # aqui o map vai aplicar a tokenização a todos os elementos do dataset\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found cached dataset multi_news (/home/azureuser/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6343d381886f4297825fb116e2de2377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Loading cached processed dataset at /home/azureuser/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72/cache-871d40ca3f50d3b5.arrow\nLoading cached processed dataset at /home/azureuser/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72/cache-7506a25ba01408fb.arrow\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1681405490715
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega a arquitetura da rede neuronal T5 a ser usada para treinar o nosso modelo e o tokenizer com o vocabulário \"t5-base\""
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1681405494996
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é definido os parametros de treino do modelo, é criado o modelo e é treinado o modelo com variação de hiperparametros"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training(trial):\n",
        "    # Teste hyierparametros, 3 valores diferentes para learning rate, weight decay e epochs, usados com combinações aleatórias \n",
        "    learning_rate = trial.suggest_categorical(\n",
        "        \"learning_rate\", [1e-5, 2e-5 ,5e-5, 1e-4])\n",
        "    weight_decay = trial.suggest_categorical(\"weight_decay\", [0.0, 0.01, 0.005, 0.001])\n",
        "    num_epochs = trial.suggest_categorical(\"num_epochs\", [1,2,3])\n",
        "       \n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=num_epochs, #numero de vezes que o dataset vai ser corrido no treino\n",
        "        per_device_train_batch_size=4, # batch size refere-se à quantidade de samples que são processadas de uma vez pelo gpu neste caso\n",
        "        per_device_eval_batch_size=4, # batch size refere-se à quantidade de samples que são processadas de uma vez pelo gpu neste caso\n",
        "        gradient_accumulation_steps=4, # usado p reduzir batches em mini batches quando fica muito pesado em termos de memória\n",
        "        evaluation_strategy=\"epoch\", #tipo de avaliação do modelo, estamos a utilizar avaliação por epoch\n",
        "        fp16=True, # mixed precision, torna o modelo mais eficiente ao utilizar valores float de 16 e 32 bits, o que pode aumentar velocidade e torna mais eficiente em memória, só funciona se for utilizado CUDA\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=10, #nm de modelos que grava\n",
        "        logging_dir=\"./logs\",\n",
        "        learning_rate=learning_rate, #pensar no declive, quanto maior pode saltar dados e n converge, quanto menor pode demorar mt a convergir e pode não atingir min globais\n",
        "        weight_decay=weight_decay,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"loss\",\n",
        "        greater_is_better=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_val_dataset,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)], #define quantos epochs precisa sem melhoria para parar de treinar \n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    return metrics[\"eval_loss\"]\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1681405495201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aval = optuna.create_study(direction=\"minimize\") #otimizar hiperparametros para minimizar loss do modelo\n",
        "aval.optimize(model_training, n_trials=10) #quantas combinações de hiperparametros vai fazer, se for 10 ele vai fazer 10 combinações possíveis"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32m[I 2023-04-13 17:04:55,006]\u001b[0m A new study created in memory with name: no-name-f821208c-2185-407d-9c59-c90bef7fb7f9\u001b[0m\n/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [140/140 25:25, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>3.188620</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Attempted to log scalar metric eval_loss:\n2.535486936569214\nAttempted to log scalar metric eval_runtime:\n61.6075\nAttempted to log scalar metric eval_samples_per_second:\n4.561\nAttempted to log scalar metric eval_steps_per_second:\n1.152\nAttempted to log scalar metric epoch:\n1.0\nAttempted to log scalar metric eval_loss:\n2.5067856311798096\nAttempted to log scalar metric eval_runtime:\n62.6843\nAttempted to log scalar metric eval_samples_per_second:\n4.483\nAttempted to log scalar metric eval_steps_per_second:\n1.133\nAttempted to log scalar metric epoch:\n1.0\nAttempted to log scalar metric eval_loss:\n3.18861985206604\nAttempted to log scalar metric eval_runtime:\n62.6416\nAttempted to log scalar metric eval_samples_per_second:\n4.486\nAttempted to log scalar metric eval_steps_per_second:\n1.133\nAttempted to log scalar metric epoch:\n1.0\nAttempted to log scalar metric train_runtime:\n1536.1302\nAttempted to log scalar metric train_samples_per_second:\n1.463\nAttempted to log scalar metric train_steps_per_second:\n0.091\nAttempted to log scalar metric total_flos:\n1364065674854400.0\nAttempted to log scalar metric train_loss:\n5.002576119559151\nAttempted to log scalar metric epoch:\n1.0\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [71/71 01:00]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Attempted to log scalar metric eval_loss:\n3.18861985206604\nAttempted to log scalar metric eval_runtime:\n61.6706\nAttempted to log scalar metric eval_samples_per_second:\n4.556\nAttempted to log scalar metric eval_steps_per_second:\n1.151\nAttempted to log scalar metric epoch:\n1.0\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='199' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [199/420 34:46 < 39:00, 0.09 it/s, Epoch 1.41/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>2.806576</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Attempted to log scalar metric eval_loss:\n2.8065762519836426\nAttempted to log scalar metric eval_runtime:\n62.6641\nAttempted to log scalar metric eval_samples_per_second:\n4.484\nAttempted to log scalar metric eval_steps_per_second:\n1.133\nAttempted to log scalar metric epoch:\n1.0\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1681405432509
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = aval.best_params #melhores hiperparametros de todos os testes feitos\n",
        "print(\"Best hyperparameters:\", best_params)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best hyperparameters: {'learning_rate': 1e-05, 'weight_decay': 0.01, 'num_epochs': 1}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1681425278544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "    summarizer = pipeline(\"summarization\", model=\"./results/checkpoint-843\", tokenizer=\"t5-base\")\n",
        "\n",
        "    t5_input = \"summarize: \" + text # o modelo t5 precisa de ter \"summarize: \" como prefixo p sumarizar\n",
        "\n",
        "    summary = summarizer(t5_input, min_length=30, max_length=150, num_beams=4, early_stopping=True)\n",
        "    summarized_text = summary[0][\"summary_text\"]\n",
        "\n",
        "    print(summarized_text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1681405432581
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}