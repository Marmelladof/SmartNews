{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Instalação das packages e importação das mesmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1681472582439
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (4.28.0)\n",
            "Requirement already satisfied: datasets in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (2.11.0)\n",
            "Requirement already satisfied: torch in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (2.0.0)\n",
            "Requirement already satisfied: optuna in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (3.1.1)\n",
            "Requirement already satisfied: sentencepiece in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (0.1.98)\n",
            "Requirement already satisfied: wandb in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (0.14.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (2023.3.23)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: multiprocess in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from datasets) (11.0.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: typing-extensions in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: sympy in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (3.0)\n",
            "Requirement already satisfied: wheel in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (61.2.0)\n",
            "Requirement already satisfied: lit in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (1.10.3)\n",
            "Requirement already satisfied: colorlog in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (2.0.9)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (1.19.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: pathtools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from wandb) (3.1.30)\n",
            "Requirement already satisfied: importlib-resources in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Requirement already satisfied: importlib-metadata in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: Mako in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jinja2->torch) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.11.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers datasets torch optuna sentencepiece wandb\n",
        "import torch\n",
        "import optuna\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config, Trainer, TrainingArguments, pipeline, EarlyStoppingCallback\n",
        "from datasets import load_dataset\n",
        "import wandb\n",
        "from transformers.integrations import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Login no weights & biases para fazer plot do treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1681472584817
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/azureuser/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key=\"fd025546a653d692020ef72e4c1779479088b079\") # maneira mais segura de passar uma key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Load do dataset \"_multi news_\" da bilbioteca _datasets_ que contem notícias e o respetivo sumário\n",
        "<br>O dataset vem com 3 splits, _train, validation e test_\n",
        "<br>Para o treino e selecionou-se só parte do dataset devido a este ser muito grande e necessitar de demasiada memória no treino do modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1681472585994
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset multi_news (/home/azureuser/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56dae78cafbe4533aa31654a318568cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset(\"multi_news\") #load ao dataset\n",
        "\n",
        "trainPercentage = int(1 * len(dataset[\"train\"])) #arranjar x% do tamanho do dataset\n",
        "\n",
        "trainSplit = dataset[\"train\"].select(range(trainPercentage)) #selecionar só x% do dataset de treino\n",
        "validationSplit = dataset[\"validation\"] #seleccionar o dataset de validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t5 = \"t5-base\"\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(t5) # carrega o modelo T5 \n",
        "tokenizer = T5Tokenizer.from_pretrained(t5) # carrega o tokenizer T5 com o vocabulário pré-treinado do t5-base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Função de tokenização usando o modelo  _T5Tokenizer_ e ficheiro de vocabulário _t5-base_\n",
        "<br> Retorna _input ids, attention mask e labels_ que são usados no treino do modelo\n",
        "<br> Feita a tokenização do dataset de treino e de validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1681472586231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /home/azureuser/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72/cache-96184cf5118120ec.arrow\n",
            "Loading cached processed dataset at /home/azureuser/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72/cache-b1a40954ff931d0c.arrow\n"
          ]
        }
      ],
      "source": [
        "def preprocess(data):\n",
        "    tokenizedInput = tokenizer(data['document'], padding=True, truncation=True, return_tensors=\"pt\", max_length=512) # faz tokenização das notícias, o que será a \"entrada\" na nossa aplicação, pt pq estamos a usar pytorch\n",
        "\n",
        "    tokenizedTarget = tokenizer(data['summary'], padding=True, truncation=True, return_tensors=\"pt\", max_length=150) # faz tokenização dos sumários, ou \"saída\", alterar o pt p tf se formos usar tensorflow\n",
        "\n",
        "    return {'input_ids': tokenizedInput['input_ids'], 'attention_mask': tokenizedInput['attention_mask'], \n",
        "            'labels': tokenizedTarget['input_ids']} # t5 necessita de input ids, attention mask e labels para treinar\n",
        "\n",
        "tokenizedTrain = trainSplit.map(preprocess, batched=True, batch_size=16) # aqui o map vai aplicar a tokenização a todos os elementos do dataset\n",
        "tokenizedValidation = validationSplit.map(preprocess, batched=True, batch_size=16) # aqui o map vai aplicar a tokenização a todos os elementos do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Aqui é definido os parametros de treino do modelo, é criado o modelo e é treinado o modelo com variação de hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1681472590137
        }
      },
      "outputs": [],
      "source": [
        "def model_training(trial):\n",
        "    # Teste hyierparametros, 3 valores diferentes para learning rate, weight decay e epochs, usados com combinações aleatórias \n",
        "    learningRate = trial.suggest_categorical(\n",
        "        \"learning_rate\", [1e-5, 2e-5 ,5e-5, 1e-4])\n",
        "    weightDecay = trial.suggest_categorical(\"weight_decay\", [0.0, 0.01, 0.005, 0.001])\n",
        "    epochs = trial.suggest_categorical(\"num_epochs\", [1,2,3])\n",
        "       \n",
        "    args = TrainingArguments(\n",
        "        # tipo de avaliação do modelo, estamos a utilizar avaliação por epoch\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        # numero de vezes que o dataset vai ser corrido no treino\n",
        "        num_train_epochs=epochs,\n",
        "        # batch size refere-se à quantidade de samples que são processadas de uma vez pelo gpu neste caso\n",
        "        per_device_train_batch_size=4,\n",
        "        # batch size refere-se à quantidade de samples que são processadas de uma vez pelo gpu neste caso\n",
        "        per_device_eval_batch_size=4,\n",
        "        # usado p reduzir batches em mini batches quando fica muito pesado em termos de memória\n",
        "        gradient_accumulation_steps=4,\n",
        "        fp16=True,  # mixed precision, torna o modelo mais eficiente ao utilizar valores float de 16 e 32 bits, o que pode aumentar velocidade e torna mais eficiente em memória, só funciona se for utilizado CUDA\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=10,  # nm de modelos que grava\n",
        "        # pensar no declive, quanto maior pode saltar dados e n converge, quanto menor pode demorar mt a convergir e pode não atingir min globais\n",
        "        learning_rate=learningRate,\n",
        "        weight_decay=weightDecay,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"loss\",\n",
        "        greater_is_better=False,\n",
        "        output_dir=\"./results\",\n",
        "        logging_dir=\"./logs\",\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tokenizedTrain,\n",
        "        eval_dataset=tokenizedValidation,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2),WandbCallback], #define quantos epochs precisa sem melhoria para parar de treinar \n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    return metrics[\"eval_loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1681543559910
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1190593\u001b[0m (\u001b[33maitiv8\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-k80/code/Users/francisco.ferreira/wandb/run-20230414_114310-y0we9vs6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aitiv8/uncategorized/runs/y0we9vs6' target=\"_blank\">polished-firefly-1</a></strong> to <a href='https://wandb.ai/aitiv8/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aitiv8/uncategorized' target=\"_blank\">https://wandb.ai/aitiv8/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aitiv8/uncategorized/runs/y0we9vs6' target=\"_blank\">https://wandb.ai/aitiv8/uncategorized/runs/y0we9vs6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-14 11:43:14,712]\u001b[0m A new study created in memory with name: no-name-394cef1c-dbe4-4d0d-8b96-2bb5b3bd2834\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 2:18:54, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.885274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.753945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.730504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.8852741718292236\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.1953\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.423\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.7539453506469727\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1270.8467\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.424\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "2.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.730504035949707\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.8555\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.42\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n",
            "Attempted to log scalar metric train_runtime:\n",
            "8344.6234\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.808\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.05\n",
            "Attempted to log scalar metric total_flos:\n",
            "4092197024563200.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "3.5662853422619047\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-14 14:23:35,071]\u001b[0m Trial 0 finished with value: 2.730504035949707 and parameters: {'learning_rate': 1e-05, 'weight_decay': 0.005, 'num_epochs': 3}. Best is trial 0 with value: 2.730504035949707.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 2:18:10, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.510101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.480898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.477335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.730504035949707\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.8771\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.413\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.510101318359375\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.9445\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.42\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.4808976650238037\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.0855\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.423\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "2.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.477335214614868\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.0037\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.423\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n",
            "Attempted to log scalar metric train_runtime:\n",
            "8300.4345\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.812\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.051\n",
            "Attempted to log scalar metric total_flos:\n",
            "4092197024563200.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "2.632444835844494\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.477335214614868\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.3874\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.422\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-14 17:03:09,548]\u001b[0m Trial 1 finished with value: 2.477335214614868 and parameters: {'learning_rate': 0.0001, 'weight_decay': 0.01, 'num_epochs': 3}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 46:13, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.496024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.4960243701934814\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.7471\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.421\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric train_runtime:\n",
            "2784.6512\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.807\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.05\n",
            "Attempted to log scalar metric total_flos:\n",
            "1364065674854400.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "2.3647511073521206\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.4960243701934814\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1270.5332\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.425\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.107\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 2:18:07, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.517374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.499652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.497104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.517373561859131\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1272.0723\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.42\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.49965238571167\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1272.6954\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.417\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "2.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.4971039295196533\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.1713\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.416\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n",
            "Attempted to log scalar metric train_runtime:\n",
            "8298.216\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.813\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.051\n",
            "Attempted to log scalar metric total_flos:\n",
            "4092197024563200.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "2.3194603329613095\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-14 18:10:45,554]\u001b[0m Trial 2 finished with value: 2.4960243701934814 and parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'num_epochs': 1}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.4971039295196533\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1272.1445\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.419\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 2:18:11, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.517390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.497920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.494185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.517390251159668\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.7842\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.414\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.497919797897339\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.3944\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.415\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "2.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.494184732437134\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.1512\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.416\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n",
            "Attempted to log scalar metric train_runtime:\n",
            "8301.4635\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.812\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.051\n",
            "Attempted to log scalar metric total_flos:\n",
            "4092197024563200.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "2.2434297107514882\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-14 20:50:16,654]\u001b[0m Trial 3 finished with value: 2.4971039295196533 and parameters: {'learning_rate': 1e-05, 'weight_decay': 0.01, 'num_epochs': 3}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-04-14 23:29:50,329]\u001b[0m Trial 4 finished with value: 2.494184732437134 and parameters: {'learning_rate': 0.0001, 'weight_decay': 0.005, 'num_epochs': 3}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.494184732437134\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.7541\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.421\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 46:15, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.583086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.5830862522125244\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1272.7051\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.417\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric train_runtime:\n",
            "2785.4034\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.807\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.05\n",
            "Attempted to log scalar metric total_flos:\n",
            "1364065674854400.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "1.8239021301269531\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-04-15 00:37:26,987]\u001b[0m Trial 5 finished with value: 2.5830862522125244 and parameters: {'learning_rate': 1e-05, 'weight_decay': 0.01, 'num_epochs': 1}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 46:14, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.638741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.5830862522125244\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1270.7764\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.424\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.106\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.6387414932250977\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.6552\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.414\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric train_runtime:\n",
            "2784.9022\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.807\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.05\n",
            "Attempted to log scalar metric total_flos:\n",
            "1364065674854400.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "1.7657186235700335\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.6387414932250977\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1272.3289\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.419\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-15 01:45:04,736]\u001b[0m Trial 6 finished with value: 2.6387414932250977 and parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'num_epochs': 1}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [280/280 1:31:59, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.634543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.594498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.6345431804656982\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.4694\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.415\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.5944979190826416\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.7732\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.414\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "1.99\n",
            "Attempted to log scalar metric train_runtime:\n",
            "5530.3743\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.813\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.051\n",
            "Attempted to log scalar metric total_flos:\n",
            "2728131349708800.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "1.8080191476004464\n",
            "Attempted to log scalar metric epoch:\n",
            "1.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-15 03:38:27,550]\u001b[0m Trial 7 finished with value: 2.5944979190826416 and parameters: {'learning_rate': 0.0001, 'weight_decay': 0.01, 'num_epochs': 2}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 46:21, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.815130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.5944979190826416\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.9593\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.42\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "1.99\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.8151304721832275\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.9653\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.413\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric train_runtime:\n",
            "2791.5506\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.805\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.05\n",
            "Attempted to log scalar metric total_flos:\n",
            "1364065674854400.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "1.3928147452218191\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.8151304721832275\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1271.9275\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.42\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.105\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-15 04:46:11,531]\u001b[0m Trial 8 finished with value: 2.8151304721832275 and parameters: {'learning_rate': 1e-05, 'weight_decay': 0.001, 'num_epochs': 1}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n",
            "You are adding a <class 'transformers.integrations.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "AzureMLCallback\n",
            "TensorBoardCallback\n",
            "WandbCallback\n",
            "EarlyStoppingCallback\n",
            "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 2:18:05, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.848568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.666286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.616757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempted to log scalar metric eval_loss:\n",
            "2.8485679626464844\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.6975\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.414\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "1.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.6662864685058594\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.614\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.414\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "2.0\n",
            "Attempted to log scalar metric eval_loss:\n",
            "2.6167571544647217\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "1273.4048\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "4.415\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "1.104\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n",
            "Attempted to log scalar metric train_runtime:\n",
            "8295.52\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.813\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.051\n",
            "Attempted to log scalar metric total_flos:\n",
            "4092197024563200.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "1.8141783214750744\n",
            "Attempted to log scalar metric epoch:\n",
            "2.99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1406' max='1406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1406/1406 21:30]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "Exception in thread SockSrvRdThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
            "    sreq = self._sock_client.read_server_request()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
            "    data = self._read_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
            "    rec = self._extract_packet_bytes()\n",
            "  File \"/anaconda/envs/jupyter_env/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
            "    assert magic == ord(\"W\")\n",
            "AssertionError\n",
            "\u001b[32m[I 2023-04-15 07:25:59,407]\u001b[0m Trial 9 finished with value: 2.6167571544647217 and parameters: {'learning_rate': 2e-05, 'weight_decay': 0.01, 'num_epochs': 3}. Best is trial 1 with value: 2.477335214614868.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "wandb.init()\n",
        "aval = optuna.create_study(direction=\"minimize\") #otimizar hiperparametros para minimizar loss do modelo\n",
        "aval.optimize(model_training, n_trials=10) #quantas combinações de hiperparametros vai fazer, se for 10 ele vai fazer 10 combinações possíveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1681543560290
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'learning_rate': 0.0001, 'weight_decay': 0.01, 'num_epochs': 3}\n"
          ]
        }
      ],
      "source": [
        "best_params = aval.best_params #melhores hiperparametros de todos os testes feitos\n",
        "print(\"Best hyperparameters:\", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1681543560562
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def summarize(text):\n",
        "    summarizer = pipeline(\"summarization\", model=\"./results/checkpoint-843\", tokenizer=\"t5-base\")\n",
        "\n",
        "    t5_input = \"summarize: \" + text # o modelo t5 precisa de ter \"summarize: \" como prefixo p sumarizar\n",
        "\n",
        "    summary = summarizer(t5_input, min_length=30, max_length=150, num_beams=4, early_stopping=True)\n",
        "    summarized_text = summary[0][\"summary_text\"]\n",
        "\n",
        "    print(summarized_text)\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
